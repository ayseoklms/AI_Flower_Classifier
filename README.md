# Yapay Zeka Destekli Ã‡iÃ§ek SÄ±nÄ±flandÄ±rÄ±cÄ± ğŸŒ¸

## 1. Projeye Genel BakÄ±ÅŸ

Bu proje, gÃ¶rsel tanÄ±ma alanÄ±nda pratik bir uygulama geliÅŸtirmeyi amaÃ§lamaktadÄ±r. PyTorch kÃ¼tÃ¼phanesi kullanÄ±larak, ImageNet Ã¼zerinde Ã¶nceden eÄŸitilmiÅŸ bir ResNet18 modeli, 5 farklÄ± Ã§iÃ§ek tÃ¼rÃ¼nÃ¼ (papatya, karahindiba, gÃ¼l, ayÃ§iÃ§eÄŸi, lale) iÃ§eren Ã¶zel bir veri seti Ã¼zerinde ince ayar (fine-tuning) yÃ¶ntemiyle eÄŸitilmiÅŸtir. EÄŸitilmiÅŸ model, kullanÄ±cÄ±larÄ±n web tarayÄ±cÄ±larÄ± Ã¼zerinden kolayca eriÅŸip Ã§iÃ§ek resimleri yÃ¼kleyerek tÃ¼r tahmini yapabilmeleri iÃ§in Gradio kÃ¼tÃ¼phanesi ile oluÅŸturulan interaktif bir web arayÃ¼zÃ¼ne entegre edilmiÅŸtir.

**Projenin Temel AmacÄ±:** Makine Ã¶ÄŸrenimi tekniklerini kullanarak, belirli bir gÃ¶rsel sÄ±nÄ±flandÄ±rma problemini Ã§Ã¶zmek ve bu Ã§Ã¶zÃ¼mÃ¼ son kullanÄ±cÄ±ya basit, anlaÅŸÄ±lÄ±r ve iÅŸlevsel bir arayÃ¼zle sunmaktÄ±r.

## 2. Ã–zellikler ve Yetenekler âœ¨

*   **GÃ¶rÃ¼ntÃ¼ YÃ¼kleme:** KullanÄ±cÄ±lar, yerel disklerinden `.jpg`, `.png` gibi yaygÄ±n formatlardaki Ã§iÃ§ek resimlerini yÃ¼kleyebilirler.
*   **Otomatik Ã–n Ä°ÅŸleme:** YÃ¼klenen gÃ¶rÃ¼ntÃ¼ler, modelin beklediÄŸi formata getirilmek Ã¼zere otomatik olarak yeniden boyutlandÄ±rÄ±lÄ±r, kÄ±rpÄ±lÄ±r ve normalize edilir.
*   **SÄ±nÄ±flandÄ±rma:** Model, yÃ¼klenen gÃ¶rÃ¼ntÃ¼yÃ¼ analiz ederek 5 Ã¶nceden tanÄ±mlanmÄ±ÅŸ Ã§iÃ§ek sÄ±nÄ±fÄ±ndan hangisine ait olduÄŸunu tahmin eder:
    1.  Papatya (Daisy)
    2.  Karahindiba (Dandelion)
    3.  GÃ¼l (Rose)
    4.  AyÃ§iÃ§eÄŸi (Sunflower)
    5.  Lale (Tulip)
*   **SonuÃ§ GÃ¶sterimi:** Tahmin edilen sÄ±nÄ±f adÄ± ve modelin her sÄ±nÄ±f iÃ§in hesapladÄ±ÄŸÄ± olasÄ±lÄ±k deÄŸerleri, kullanÄ±cÄ± dostu bir etiket formatÄ±nda gÃ¶sterilir.
*   **Ä°nteraktif Web ArayÃ¼zÃ¼:** Gradio ile geliÅŸtirilen arayÃ¼z, web tarayÄ±cÄ±sÄ± Ã¼zerinden kolay eriÅŸim ve kullanÄ±m imkanÄ± sunar. Ã–rnek resimlerle hÄ±zlÄ± test imkanÄ± saÄŸlar.
*   **Ä°nce AyarlÄ± Model:** Temel alÄ±nan ResNet18 modeli, ImageNet'ten Ã¶ÄŸrendiÄŸi genel gÃ¶rsel Ã¶zellikleri Ã§iÃ§ek tanÄ±ma gÃ¶revine baÅŸarÄ±yla aktarmÄ±ÅŸtÄ±r.

## 3. KullanÄ±lan Teknolojiler ve KÃ¼tÃ¼phaneler ğŸ› ï¸

*   **Programlama Dili:** Python 3
*   **Derin Ã–ÄŸrenme KÃ¼tÃ¼phanesi:** PyTorch
*   **GÃ¶rÃ¼ntÃ¼ Ä°ÅŸleme ve Model:** torchvision (ResNet18, Transforms, ImageFolder)
*   **Web ArayÃ¼zÃ¼:** Gradio
*   **Veri Ä°ÅŸleme ve Metrikler:** NumPy, Scikit-learn (precision_score, recall_score)
*   **GÃ¶rselleÅŸtirme:** Matplotlib (EÄŸitim grafiklerini Ã§izmek iÃ§in)
*   **DiÄŸer:** Pillow (PIL - GÃ¶rÃ¼ntÃ¼ okuma/iÅŸleme iÃ§in)
*   **Ortam YÃ¶netimi:** `venv` (Sanal ortam), `pip` (Paket yÃ¶neticisi)

## 4. Veri Seti Bilgileri ğŸ“Š

*   **AdÄ±:** Flowers Recognition
*   **Kaynak:** [Kaggle - Flowers Recognition](https://www.kaggle.com/datasets/alxmamaev/flowers-recognition)
*   **Ä°Ã§erik:** 5 sÄ±nÄ±fa ait (daisy, dandelion, roses, sunflowers, tulips) yaklaÅŸÄ±k 4000+ etiketli gÃ¶rsel.
*   **HazÄ±rlÄ±k:** Veri seti, model eÄŸitimi ve deÄŸerlendirmesi iÃ§in `split_data.py` betiÄŸi kullanÄ±larak rastgele bir ÅŸekilde EÄŸitim (%80) ve DoÄŸrulama (%20) alt kÃ¼melerine ayrÄ±lmÄ±ÅŸtÄ±r. Bu iÅŸlem sonucunda proje dizininde `data/train` ve `data/validation` klasÃ¶rleri oluÅŸturulmuÅŸtur.

## 5. Kurulum ve HazÄ±rlÄ±k AdÄ±mlarÄ± âš™ï¸

Projeyi kendi bilgisayarÄ±nÄ±zda Ã§alÄ±ÅŸtÄ±rmak iÃ§in aÅŸaÄŸÄ±daki adÄ±mlarÄ± takip ediniz:

1.  **Depoyu Klonlama veya Ä°ndirme:**
    *   *(GitHub deposu oluÅŸturulduktan sonra aÅŸaÄŸÄ±daki komutlarÄ± gÃ¼ncelleyebilirsiniz)*
    *   GitHub kullanÄ±yorsanÄ±z:
        ```bash
        git clone <github_repo_linkiniz> # Bu linki kendi reponuzla deÄŸiÅŸtirin
        cd <proje_klasor_adiniz>
        ```
    *   Veya ZIP olarak indirip dosyalarÄ± bir klasÃ¶re Ã§Ä±kartÄ±n ve o klasÃ¶re gidin.

2.  **Veri Setini Ayarlama:**
    *   [Kaggle'dan](https://www.kaggle.com/datasets/alxmamaev/flowers-recognition) veri setini (`archive.zip`) indirin.
    *   Ä°ndirdiÄŸiniz zip dosyasÄ±nÄ± **proje klasÃ¶rÃ¼nÃ¼zÃ¼n dÄ±ÅŸÄ±ndaki** bir yere Ã§Ä±kartÄ±n (Ã¶rneÄŸin, `Downloads/flowers`).
    *   Proje klasÃ¶rÃ¼nÃ¼zdeki `split_data.py` dosyasÄ±nÄ± bir metin dÃ¼zenleyici ile aÃ§Ä±n.
    *   `SOURCE_DIR` deÄŸiÅŸkenini, az Ã¶nce zip'ten Ã§Ä±kardÄ±ÄŸÄ±nÄ±z `flowers` klasÃ¶rÃ¼nÃ¼n **tam yolu** ile gÃ¼ncelleyin (Windows iÃ§in `r"C:\..."` formatÄ±nÄ± kullanÄ±n).
    *   `DEST_DIR` deÄŸiÅŸkeninin, proje klasÃ¶rÃ¼nÃ¼zÃ¼n iÃ§indeki `data` klasÃ¶rÃ¼nÃ¼ iÅŸaret ettiÄŸinden emin olun (genellikle `r"C:\...<proje_klasor_yolu>\data"` gibi).
    *   Terminalde sanal ortamÄ± aktive ettikten sonra ÅŸu komutu Ã§alÄ±ÅŸtÄ±rÄ±n:
        ```bash
        python split_data.py
        ```
        *(Bu iÅŸlem `data/train` ve `data/validation` klasÃ¶rlerini oluÅŸturacak/dolduracaktÄ±r.)*

3.  **Sanal Ortam Kurulumu:**
    *   Proje ana dizininde terminali aÃ§Ä±n.
    *   `python -m venv venv` komutu ile sanal ortamÄ± oluÅŸturun.
    *   Sanal ortamÄ± aktive edin:
        *   Windows: `.\venv\Scripts\activate`
        *   macOS/Linux: `source venv/bin/activate`
    *   *(Terminal baÅŸÄ±nda `(venv)` gÃ¶rmelisiniz.)*

4.  **BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleme:**
    *   Aktif sanal ortamda ÅŸu komutu Ã§alÄ±ÅŸtÄ±rÄ±n:
        ```bash
        pip install -r requirements.txt
        ```
    *   **GPU Notu:** EÄŸer CUDA destekli NVIDIA GPU kullanmak isterseniz ve PyTorch kurulumunda sorun yaÅŸarsanÄ±z, [PyTorch'un resmi sitesinden](https://pytorch.org/get-started/locally/) sisteminize uygun CUDA versiyonu iÃ§in verilen `pip install ...` komutunu Ã§alÄ±ÅŸtÄ±rmanÄ±z gerekebilir.

## 6. UygulamanÄ±n KullanÄ±mÄ± ğŸš€

Kurulum adÄ±mlarÄ± tamamlandÄ±ktan sonra uygulamayÄ± iki ÅŸekilde kullanabilirsiniz:

**A. Modeli Yeniden EÄŸitme (Opsiyonel):**

EÄŸer modeli kendi veri setinizle veya farklÄ± ayarlarla eÄŸitmek isterseniz:

1.  Sanal ortamÄ±n aktif olduÄŸundan emin olun (`(venv)`).
2.  Terminalde ÅŸu komutu Ã§alÄ±ÅŸtÄ±rÄ±n:
    ```bash
    python train.py
    ```
3.  EÄŸitim sÃ¼reci baÅŸlayacak, her epoch sonunda metrikler yazdÄ±rÄ±lacak ve eÄŸitim bittiÄŸinde performans grafikleri (`grafik_goruntu.png` benzeri) gÃ¶sterilecektir. EÄŸitilmiÅŸ model aÄŸÄ±rlÄ±klarÄ± otomatik olarak `cicek_siniflandirici_resnet18.pth` dosyasÄ±na kaydedilecektir.

**B. Web ArayÃ¼zÃ¼nÃ¼ Ã‡alÄ±ÅŸtÄ±rma (Tahmin Yapma):**

EÄŸitilmiÅŸ modeli kullanarak tahmin yapmak iÃ§in:

1.  Sanal ortamÄ±n aktif olduÄŸundan emin olun (`(venv)`).
2.  Terminalde ÅŸu komutu Ã§alÄ±ÅŸtÄ±rÄ±n:
    ```bash
    python app.py
    ```
3.  Terminalde `Running on local URL: http://127.0.0.1:XXXX` ÅŸeklinde bir adres belirecektir.
4.  Bu adresi kopyalayÄ±p **web tarayÄ±cÄ±nÄ±za** yapÄ±ÅŸtÄ±rÄ±n.
5.  AÃ§Ä±lan Gradio arayÃ¼zÃ¼nde "Ã‡iÃ§ek Resmi YÃ¼kle" alanÄ±na tÄ±klayarak veya sÃ¼rÃ¼kleyerek bir resim yÃ¼kleyin ya da saÄŸlanan Ã¶rnek resimlerden birini seÃ§in.
6.  Modelin tahmin sonuÃ§larÄ± (sÄ±nÄ±f adÄ± ve olasÄ±lÄ±klarÄ±) arayÃ¼zde gÃ¶rÃ¼necektir.

## 7. Model PerformansÄ± ve SonuÃ§lar ğŸ“ˆ

Model, ResNet18 mimarisi temel alÄ±narak ve ImageNet Ã¼zerinde Ã¶nceden eÄŸitilmiÅŸ aÄŸÄ±rlÄ±klar kullanÄ±larak, saÄŸlanan Ã§iÃ§ek veri seti Ã¼zerinde **15 epoch** boyunca ince ayara tabi tutulmuÅŸtur. Adam optimizer (lr=0.001) ve CrossEntropyLoss kullanÄ±lmÄ±ÅŸtÄ±r. Elde edilen en iyi **doÄŸrulama seti (validation set)** performansÄ± aÅŸaÄŸÄ±daki gibidir (Epoch 13'te elde edilmiÅŸtir):

*   **En Ä°yi DoÄŸrulama BaÅŸarÄ±sÄ± (Accuracy):** **%89.48** (0.8948)
*   **En Ä°yi DoÄŸrulama Precision (Macro Avg.):** **0.8944**
*   **En Ä°yi DoÄŸrulama Recall (Macro Avg.):** **0.8971**

*(Bu deÄŸerler, `train.py` betiÄŸinin son Ã§alÄ±ÅŸtÄ±rÄ±lmasÄ± sonucunda elde edilmiÅŸtir.)*

EÄŸitim sÃ¼reci boyunca metriklerin epoch'lara gÃ¶re deÄŸiÅŸimi aÅŸaÄŸÄ±daki grafiklerde gÃ¶rÃ¼lebilir:

![EÄŸitim Grafikleri](grafik_goruntu.png)

## 8. Uygulama ArayÃ¼zÃ¼ Ekran GÃ¶rÃ¼ntÃ¼sÃ¼ ğŸ“¸

![Gradio Ã‡iÃ§ek SÄ±nÄ±flandÄ±rÄ±cÄ± ArayÃ¼zÃ¼](arayuz_goruntusu_and_output.png)

## 9. OlasÄ± GeliÅŸtirmeler ve Gelecek Ã‡alÄ±ÅŸmalar ğŸ’¡

*   **Hiperparametre Optimizasyonu:** Ã–ÄŸrenme oranÄ±, batch boyutu, epoch sayÄ±sÄ± gibi parametrelerle deneyler yaparak model performansÄ± iyileÅŸtirilebilir.
*   **GeliÅŸmiÅŸ Veri ArtÄ±rma:** Daha fazla veya farklÄ± veri artÄ±rma teknikleri (`torchvision.transforms` iÃ§inde veya Albumentations gibi kÃ¼tÃ¼phanelerle) uygulanabilir.
*   **FarklÄ± Modeller:** ResNet34, EfficientNet veya Vision Transformer (ViT) gibi daha bÃ¼yÃ¼k veya farklÄ± mimariler denenebilir.
*   **DetaylÄ± DeÄŸerlendirme:** KarÄ±ÅŸÄ±klÄ±k matrisi (Confusion Matrix) oluÅŸturularak modelin hangi sÄ±nÄ±flarÄ± karÄ±ÅŸtÄ±rdÄ±ÄŸÄ± analiz edilebilir. Scikit-learn'Ã¼n `classification_report` fonksiyonu ile sÄ±nÄ±f bazÄ±nda metrikler incelenebilir.
*   **Deployment:** Model, kalÄ±cÄ± bir web uygulamasÄ± olarak Hugging Face Spaces, Streamlit Cloud, Heroku, AWS/GCP/Azure gibi platformlara deploy edilebilir.
*   **SÄ±nÄ±f SayÄ±sÄ±nÄ± ArtÄ±rma:** Daha fazla Ã§iÃ§ek tÃ¼rÃ¼ iÃ§eren bir veri seti ile model yeniden eÄŸitilebilir.

## 10. Lisans ğŸ“„

Bu proje MIT LisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in depodaki `LICENSE` dosyasÄ±na bakÄ±nÄ±z (veya [MIT Lisans metnine](https://opensource.org/licenses/MIT) bakÄ±nÄ±z).

---

*Bu README dosyasÄ±, projenin anlaÅŸÄ±lmasÄ±na ve kullanÄ±lmasÄ±na yardÄ±mcÄ± olmak amacÄ±yla hazÄ±rlanmÄ±ÅŸtÄ±r.*